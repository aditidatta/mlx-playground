{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Notebook to Try Out MLX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f92ed21ad1d44c99144547552ef415b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Hello. I can help in various ways, such as:\n",
      "\n",
      "1. **Answering questions**: I can process natural language queries and provide relevant answers, covering a wide range of topics from science and history to entertainment and culture.\n",
      "2. **Generating text**: I can create text based on a prompt, topic, or style. This can be useful for writing articles, creating stories, or even composing emails.\n",
      "3. **Translation**: I can translate text from one language to another, including popular languages such as Spanish, French, German, Chinese, and many more.\n",
      "4. **Summarization**: I can summarize long pieces of text into shorter, more digestible versions, highlighting key points and main ideas.\n",
      "5. **Creative writing**: I can engage in creative writing, such as poetry or short stories, and even offer suggestions for writing prompts.\n",
      "6. **Conversation**: I can have a conversation with you, using context and understanding to respond to questions and statements.\n",
      "7. **Jokes and humor**: I can share jokes and try to be humorous, though I'm still learning what humans find funny.\n",
      "8. **Trivia and games**: I can participate in trivia games, and even create simple games or challenges for you to solve.\n",
      "9. **Language learning**: I can\n",
      "==========\n",
      "Prompt: 49 tokens, 66.779 tokens-per-sec\n",
      "Generation: 256 tokens, 16.649 tokens-per-sec\n",
      "Peak memory: 79.559 GB\n",
      "Hello. I can help in various ways, such as:\n",
      "\n",
      "1. **Answering questions**: I can process natural language queries and provide relevant answers, covering a wide range of topics from science and history to entertainment and culture.\n",
      "2. **Generating text**: I can create text based on a prompt, topic, or style. This can be useful for writing articles, creating stories, or even composing emails.\n",
      "3. **Translation**: I can translate text from one language to another, including popular languages such as Spanish, French, German, Chinese, and many more.\n",
      "4. **Summarization**: I can summarize long pieces of text into shorter, more digestible versions, highlighting key points and main ideas.\n",
      "5. **Creative writing**: I can engage in creative writing, such as poetry or short stories, and even offer suggestions for writing prompts.\n",
      "6. **Conversation**: I can have a conversation with you, using context and understanding to respond to questions and statements.\n",
      "7. **Jokes and humor**: I can share jokes and try to be humorous, though I'm still learning what humans find funny.\n",
      "8. **Trivia and games**: I can participate in trivia games, and even create simple games or challenges for you to solve.\n",
      "9. **Language learning**: I can\n"
     ]
    }
   ],
   "source": [
    "from mlx_lm import load, generate\n",
    "\n",
    "model, tokenizer = load(\"mlx-community/Meta-Llama-3.1-70B-Instruct-4bit\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"hello, how can you help me?\"}\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "response = generate(model, tokenizer, prompt, verbose=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del tokenizer\n",
    "\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import mlx.core as mx\n",
    "mx.metal.clear_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
